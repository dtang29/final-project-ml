{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681\n",
      "['business_name', 'lic_code', 'street_address', 'business_start_date', 'business_end_date', 'Lifespan', 'isClosed', 'full_address', 'business_id', 'name', 'district', 'MA', 'year', 'latitude', 'longitude', 'tract', 'GEOID10', 'link', 'HC01_VC05', 'HC01_VC113', 'HC01_VC115', 'HC01_VC117', 'HC01_VC121', 'HC01_VC28', 'HC01_VC36', 'HC01_VC41', 'HC01_VC42', 'HC01_VC43', 'HC01_VC44', 'HC01_VC50', 'HC01_VC51', 'HC01_VC52', 'HC01_VC53', 'HC01_VC54', 'HC01_VC55', 'HC01_VC56', 'HC01_VC57', 'HC01_VC58', 'HC01_VC59', 'HC01_VC60', 'HC01_VC61', 'HC01_VC62', 'HC01_VC67', 'HC01_VC68', 'HC01_VC69', 'HC01_VC85', 'HC01_VC86', 'HC01_VC89', 'HC01_VC99', 'HC03_VC05', 'HC03_VC13', 'HC03_VC156', 'HC03_VC28', 'HC03_VC41', 'HC03_VC42', 'HC03_VC43', 'HC03_VC44', 'HC03_VC45', 'HC03_VC50', 'HC03_VC51', 'HC03_VC52', 'HC03_VC53', 'HC03_VC54', 'HC03_VC55', 'HC03_VC56', 'HC03_VC57', 'HC03_VC58', 'HC03_VC59', 'HC03_VC60', 'HC03_VC61', 'HC03_VC62', 'HC03_VC67', 'HC03_VC68', 'HC03_VC69', 'HC03_VC75', 'HC03_VC76', 'HC03_VC77', 'HC03_VC78', 'HC03_VC79', 'HC03_VC80', 'HC03_VC81', 'HC03_VC82', 'HC03_VC83', 'HC03_VC84', 'HD01_S001', 'HD01_S020', 'HD01_S026', 'HD01_S045', 'HD01_S051', 'HD01_S070', 'HD01_S151', 'HD01_S169', 'HD01_S170', 'HD01_S171', 'HD01_S180', 'HD01_S181', 'HD01_S184', 'HD02_S026', 'HD02_S051', 'HD02_S151', 'HD02_S170', 'HD02_S171', 'HD02_S180', 'HD02_S181', 'HD02_S184', 'Opening_year', 'Closing_year', 'Opening_month', 'Closing_month', 'input_string', 'price_level', 'rating', 'business_name.1', 'Q1_16_Nature_Exp', 'Q2_16_Nature_Exp', 'Q3_16_Nature_Exp', 'Q4_16_Nature_Exp', 'Q1_17_Nature_Exp', 'Q2_17_Nature_Exp', 'Q3_17_Nature_Exp', 'Q4_17_Nature_Exp', 'Q1_16_Family_Fun', 'Q2_16_Family_Fun', 'Q3_16_Family_Fun', 'Q4_16_Family_Fun', 'Q1_17_Family_Fun', 'Q2_17_Family_Fun', 'Q3_17_Family_Fun', 'Q4_17_Family_Fun', 'Q1_16_Healthy_Lifestyle', 'Q2_16_Healthy_Lifestyle', 'Q3_16_Healthy_Lifestyle', 'Q4_16_Healthy_Lifestyle', 'Q1_17_Healthy_Lifestyle', 'Q2_17_Healthy_Lifestyle', 'Q3_17_Healthy_Lifestyle', 'Q4_17_Healthy_Lifestyle', 'Q1_16_Nightlife_Hotspot', 'Q2_16_Nightlife_Hotspot', 'Q3_16_Nightlife_Hotspot', 'Q4_16_Nightlife_Hotspot', 'Q1_17_Nightlife_Hotspot', 'Q2_17_Nightlife_Hotspot', 'Q3_17_Nightlife_Hotspot', 'Q4_17_Nightlife_Hotspot', 'Q1_16_Artsy', 'Q2_16_Artsy', 'Q3_16_Artsy', 'Q4_16_Artsy', 'Q1_17_Artsy', 'Q2_17_Artsy', 'Q3_17_Artsy', 'Q4_17_Artsy', 'Q1_16_Foodie', 'Q2_16_Foodie', 'Q3_16_Foodie', 'Q4_16_Foodie', 'Q1_17_Foodie', 'Q2_17_Foodie', 'Q3_17_Foodie', 'Q4_17_Foodie', 'Q1_16_Hipster', 'Q2_16_Hipster', 'Q3_16_Hipster', 'Q4_16_Hipster', 'Q1_17_Hipster', 'Q2_17_Hipster', 'Q3_17_Hipster', 'Q4_17_Hipster', 'Q1_16_Beautiful_Scenery', 'Q2_16_Beautiful_Scenery', 'Q3_16_Beautiful_Scenery', 'Q4_16_Beautiful_Scenery', 'Q1_17_Beautiful_Scenery', 'Q2_17_Beautiful_Scenery', 'Q3_17_Beautiful_Scenery', 'Q4_17_Beautiful_Scenery', 'Foodie_16', 'Foodie_17', 'lic_code_cat', 'district_cat', 'Nature_Exp', 'Family_Fun', 'Healthy_Lifestyle', 'Nightlife_Hotspot', 'Artsy', 'Foodie', 'Hipster', 'Beautiful_Scenery']\n"
     ]
    }
   ],
   "source": [
    "df_csv = pd.read_csv('cleanDatasets/master_dataset2010.csv')\n",
    "df = pd.DataFrame(df_csv)\n",
    "print(len(df))\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df[[\n",
    "    'rating','isClosed','lic_code_cat'\n",
    "]].dropna()\n",
    "\n",
    "# Testing X Variables:\n",
    "    # 'rating','isClosed','Lifespan','MA','Opening_year','price_level','Foodie_16','Foodie_17','lic_code_cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08516886930983847% of the dataset are closed locations\n"
     ]
    }
   ],
   "source": [
    "len(df_reg)\n",
    "print(str(len(df_reg[df_reg['isClosed']==0])/len(df_reg)) + \"% of the dataset are closed locations\") # no: 1, yes: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Simple Linear Regression ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(681, 2) (681, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df_reg.drop('isClosed',axis = 1)\n",
    "y = df_reg[\"isClosed\"].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55306814] [[0.05788601 0.08346552]]\n"
     ]
    }
   ],
   "source": [
    "# Ref: https://becominghuman.ai/stats-models-vs-sklearn-for-linear-regression-f19df95ad99b\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "# X = df_reg[\"Lifespan\"].values.reshape(-1, 1)\n",
    "# y = df_reg[\"isClosed\"]\n",
    "\n",
    "model = lm.LinearRegression()\n",
    "results = model.fit(X,y)\n",
    "print(model.intercept_,model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the Prob(Omnibus) is very small, and I took this to mean <.05 as this is standard statistical practice, then our data is probably not normal. \n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   78.69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 07 Aug 2018</td> <th>  Prob (F-statistic):</th> <td>1.86e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:12:32</td>     <th>  Log-Likelihood:    </th> <td> -26.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   681</td>      <th>  AIC:               </th> <td>   58.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   678</td>      <th>  BIC:               </th> <td>   72.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    0.5531</td> <td>    0.121</td> <td>    4.559</td> <td> 0.000</td> <td>    0.315</td> <td>    0.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating</th>       <td>    0.0579</td> <td>    0.028</td> <td>    2.034</td> <td> 0.042</td> <td>    0.002</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lic_code_cat</th> <td>    0.0835</td> <td>    0.007</td> <td>   12.484</td> <td> 0.000</td> <td>    0.070</td> <td>    0.097</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>295.040</td> <th>  Durbin-Watson:     </th> <td>   2.032</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1047.913</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-2.110</td>  <th>  Prob(JB):          </th> <td>2.81e-228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.372</td>  <th>  Cond. No.          </th> <td>    59.2</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.188\n",
       "Model:                            OLS   Adj. R-squared:                  0.186\n",
       "Method:                 Least Squares   F-statistic:                     78.69\n",
       "Date:                Tue, 07 Aug 2018   Prob (F-statistic):           1.86e-31\n",
       "Time:                        18:12:32   Log-Likelihood:                -26.221\n",
       "No. Observations:                 681   AIC:                             58.44\n",
       "Df Residuals:                     678   BIC:                             72.01\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            0.5531      0.121      4.559      0.000       0.315       0.791\n",
       "rating           0.0579      0.028      2.034      0.042       0.002       0.114\n",
       "lic_code_cat     0.0835      0.007     12.484      0.000       0.070       0.097\n",
       "==============================================================================\n",
       "Omnibus:                      295.040   Durbin-Watson:                   2.032\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1047.913\n",
       "Skew:                          -2.110   Prob(JB):                    2.81e-228\n",
       "Kurtosis:                       7.372   Cond. No.                         59.2\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "print(\"If the Prob(Omnibus) is very small, and I took this to mean <.05 as this is standard statistical practice, then our data is probably not normal. \")\n",
    "print(' ')\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Prediction Model ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.18761865372735653\n",
      "Testing Score: 0.18981318474295186\n",
      "[0.59946542] [[0.         0.04681763 0.08288012]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "training_score = model.score(X_train, y_train)\n",
    "testing_score = model.score(X_test, y_test)\n",
    "\n",
    "### END SOLUTION \n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")\n",
    "print(model.intercept_,model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Residual Plot')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y.min(), xmax=y.max())\n",
    "plt.title(\"Residual Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are three primary metrics used to evaluate linear models. Mean absolute error (MAE), Mean squared error (MSE), or Root mean squared error (RMSE) 1) MAE: The easiest to understand. Represents average error 2) MSE: Similar to MAE but noise is exaggerated and larger errors are “punished”. It is harder to interpret than MAE as it’s not in base units, however, it is generally more popular 3) RMSE: Most popular metric, similar to MSE, however, the result is square rooted to make it more interpretable as it’s in base units. It is recommended that RMSE be used as the primary metric to interpret your model\n"
     ]
    }
   ],
   "source": [
    "print('There are three primary metrics used to evaluate linear models. Mean absolute error (MAE), Mean squared error (MSE), or Root mean squared error (RMSE)' + ' ' +\n",
    "'1) MAE: The easiest to understand. Represents average error' + ' ' +\n",
    "'2) MSE: Similar to MAE but noise is exaggerated and larger errors are “punished”. It is harder to interpret than MAE as it’s not in base units, however, it is generally more popular' + ' ' +\n",
    "'3) RMSE: Most popular metric, similar to MSE, however, the result is square rooted to make it more interpretable as it’s in base units. It is recommended that RMSE be used as the primary metric to interpret your model'    \n",
    "      )\n",
    "# Ref: https://towardsdatascience.com/linear-regression-in-python-9a1f5f000606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################Linear Regression (SCALED) ########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reg.drop('Lifespan',axis = 1)\n",
    "y = df_reg[\"Lifespan\"].values.reshape(-1, 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LinearRegression model and fit it to the scaled training data\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the X_test_scaled data\n",
    "# Plot y_test_scaled vs y_test_scaled\n",
    "# Scatter plot y_test_scaled vs predictions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "plt.scatter(model.predict(X_train_scaled), model.predict(X_train_scaled) - y_train_scaled, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_scaled), model.predict(X_test_scaled) - y_test_scaled, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_scaled.min(), xmax=y_test_scaled.max())\n",
    "\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.04549907878415, R2: 0.011668611500404769\n"
     ]
    }
   ],
   "source": [
    "# Used X_test_scaled, y_test_scaled, and model.predict(X_test_scaled) to calculate MSE and R2\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = model.score(X_test_scaled, y_test_scaled)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.0433279025779165, R2: 0.01372106820565544\n"
     ]
    }
   ],
   "source": [
    "# LASSO model\n",
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "lasso = Lasso(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "predictions = lasso.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = lasso.score(X_test_scaled, y_test_scaled)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.0454988680787887, R2: 0.011668810684437038\n"
     ]
    }
   ],
   "source": [
    "# Ridge model\n",
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ridge = Ridge(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "predictions = ridge.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = ridge.score(X_test_scaled, y_test_scaled)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.0442311923744525, R2: 0.012867170122965566\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet model\n",
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "elasticnet = ElasticNet(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "predictions = elasticnet.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = elasticnet.score(X_test_scaled, y_test_scaled)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################Logistic Regression #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df[[\n",
    "    'rating','lic_code_cat',\"isClosed\"\n",
    "]].dropna()\n",
    "\n",
    "# Testing X Variables:\n",
    "    # 'rating','isClosed','Lifespan','MA','Opening_year','price_level','Foodie_16','Foodie_17','lic_code_cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(681, 2) (681,)\n"
     ]
    }
   ],
   "source": [
    "X = df_reg.drop(\"isClosed\", axis=1)\n",
    "y = df_reg[\"isClosed\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9156862745098039\n",
      "Testing Data Score: 0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [1 1 1 1 1 1 1 1 1 1]\n",
      "First 10 Actual labels: [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction  Actual\n",
       "0             1       1\n",
       "1             1       1\n",
       "2             1       1\n",
       "3             1       1\n",
       "4             1       1\n",
       "5             1       1\n",
       "6             1       1\n",
       "7             1       1\n",
       "8             1       0\n",
       "9             1       1\n",
       "10            1       1\n",
       "11            1       1\n",
       "12            1       1\n",
       "13            1       1\n",
       "14            1       1\n",
       "15            1       1\n",
       "16            1       1\n",
       "17            1       1\n",
       "18            1       1\n",
       "19            1       1\n",
       "20            1       1\n",
       "21            1       1\n",
       "22            1       1\n",
       "23            1       0\n",
       "24            1       1\n",
       "25            1       1\n",
       "26            1       0\n",
       "27            1       1\n",
       "28            1       1\n",
       "29            1       1\n",
       "..          ...     ...\n",
       "141           1       0\n",
       "142           1       1\n",
       "143           1       1\n",
       "144           1       1\n",
       "145           1       1\n",
       "146           1       1\n",
       "147           1       1\n",
       "148           1       1\n",
       "149           1       1\n",
       "150           1       1\n",
       "151           1       1\n",
       "152           1       1\n",
       "153           1       1\n",
       "154           1       1\n",
       "155           1       1\n",
       "156           1       1\n",
       "157           1       1\n",
       "158           1       1\n",
       "159           1       1\n",
       "160           1       1\n",
       "161           1       1\n",
       "162           1       1\n",
       "163           1       1\n",
       "164           1       1\n",
       "165           1       1\n",
       "166           1       1\n",
       "167           1       1\n",
       "168           1       1\n",
       "169           1       1\n",
       "170           1       1\n",
       "\n",
       "[171 rows x 2 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################Logisitic Model 2 ###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.read_csv('cleanDatasets/master_dataset2015.csv')\n",
    "df = pd.DataFrame(df_csv)\n",
    "df_reg = df[[\n",
    "    'rating','isClosed','lic_code_cat'\n",
    "]].dropna()\n",
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.drop(df_reg[df_reg.lic_code_cat.isin(['-1'])].index)\n",
    "# df_reg.lic_code_cat.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030303030303030304% of the dataset are closed locations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(len(df_reg[df_reg['isClosed']==0])/len(df_reg)) + \"% of the dataset are closed locations\") # no: 1, yes: 0\n",
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 2) (231,)\n"
     ]
    }
   ],
   "source": [
    "X = df_reg.drop(\"isClosed\", axis=1)\n",
    "y = df_reg[\"isClosed\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reg.drop('isClosed',axis = 1)\n",
    "y = df_reg[\"isClosed\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.130897\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  231\n",
      "Model:                          Logit   Df Residuals:                      229\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 07 Aug 2018   Pseudo R-squ.:                 0.03606\n",
      "Time:                        20:29:22   Log-Likelihood:                -30.237\n",
      "converged:                       True   LL-Null:                       -31.368\n",
      "                                        LLR p-value:                    0.1326\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "rating           0.9244      0.213      4.346      0.000       0.508       1.341\n",
      "lic_code_cat    -0.1767      0.365     -0.484      0.628      -0.892       0.538\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.99\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "modelCV = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 0 69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.99      1.00      0.99        69\n",
      "\n",
      "avg / total       0.97      0.99      0.98        70\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\White Base\\AppData\\Local\\conda\\conda\\envs\\FinalProject\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_name', 'lic_code', 'street_address', 'business_start_date', 'business_end_date', 'Lifespan', 'isClosed', 'full_address', 'business_id', 'name', 'district', 'MA', 'year', 'latitude', 'longitude', 'tract', 'GEOID10', 'link', 'HC01_VC05', 'HC01_VC113', 'HC01_VC115', 'HC01_VC117', 'HC01_VC121', 'HC01_VC28', 'HC01_VC36', 'HC01_VC41', 'HC01_VC42', 'HC01_VC43', 'HC01_VC44', 'HC01_VC50', 'HC01_VC51', 'HC01_VC52', 'HC01_VC53', 'HC01_VC54', 'HC01_VC55', 'HC01_VC56', 'HC01_VC57', 'HC01_VC58', 'HC01_VC59', 'HC01_VC60', 'HC01_VC61', 'HC01_VC62', 'HC01_VC67', 'HC01_VC68', 'HC01_VC69', 'HC01_VC85', 'HC01_VC86', 'HC01_VC89', 'HC01_VC99', 'HC03_VC05', 'HC03_VC13', 'HC03_VC156', 'HC03_VC28', 'HC03_VC41', 'HC03_VC42', 'HC03_VC43', 'HC03_VC44', 'HC03_VC45', 'HC03_VC50', 'HC03_VC51', 'HC03_VC52', 'HC03_VC53', 'HC03_VC54', 'HC03_VC55', 'HC03_VC56', 'HC03_VC57', 'HC03_VC58', 'HC03_VC59', 'HC03_VC60', 'HC03_VC61', 'HC03_VC62', 'HC03_VC67', 'HC03_VC68', 'HC03_VC69', 'HC03_VC75', 'HC03_VC76', 'HC03_VC77', 'HC03_VC78', 'HC03_VC79', 'HC03_VC80', 'HC03_VC81', 'HC03_VC82', 'HC03_VC83', 'HC03_VC84', 'HD01_S001', 'HD01_S020', 'HD01_S026', 'HD01_S045', 'HD01_S051', 'HD01_S070', 'HD01_S151', 'HD01_S169', 'HD01_S170', 'HD01_S171', 'HD01_S180', 'HD01_S181', 'HD01_S184', 'HD02_S026', 'HD02_S051', 'HD02_S151', 'HD02_S170', 'HD02_S171', 'HD02_S180', 'HD02_S181', 'HD02_S184', 'Opening_year', 'Closing_year', 'Opening_month', 'Closing_month', 'input_string', 'price_level', 'rating', 'business_name.1', 'Q1_16_Nature_Exp', 'Q2_16_Nature_Exp', 'Q3_16_Nature_Exp', 'Q4_16_Nature_Exp', 'Q1_17_Nature_Exp', 'Q2_17_Nature_Exp', 'Q3_17_Nature_Exp', 'Q4_17_Nature_Exp', 'Q1_16_Family_Fun', 'Q2_16_Family_Fun', 'Q3_16_Family_Fun', 'Q4_16_Family_Fun', 'Q1_17_Family_Fun', 'Q2_17_Family_Fun', 'Q3_17_Family_Fun', 'Q4_17_Family_Fun', 'Q1_16_Healthy_Lifestyle', 'Q2_16_Healthy_Lifestyle', 'Q3_16_Healthy_Lifestyle', 'Q4_16_Healthy_Lifestyle', 'Q1_17_Healthy_Lifestyle', 'Q2_17_Healthy_Lifestyle', 'Q3_17_Healthy_Lifestyle', 'Q4_17_Healthy_Lifestyle', 'Q1_16_Nightlife_Hotspot', 'Q2_16_Nightlife_Hotspot', 'Q3_16_Nightlife_Hotspot', 'Q4_16_Nightlife_Hotspot', 'Q1_17_Nightlife_Hotspot', 'Q2_17_Nightlife_Hotspot', 'Q3_17_Nightlife_Hotspot', 'Q4_17_Nightlife_Hotspot', 'Q1_16_Artsy', 'Q2_16_Artsy', 'Q3_16_Artsy', 'Q4_16_Artsy', 'Q1_17_Artsy', 'Q2_17_Artsy', 'Q3_17_Artsy', 'Q4_17_Artsy', 'Q1_16_Foodie', 'Q2_16_Foodie', 'Q3_16_Foodie', 'Q4_16_Foodie', 'Q1_17_Foodie', 'Q2_17_Foodie', 'Q3_17_Foodie', 'Q4_17_Foodie', 'Q1_16_Hipster', 'Q2_16_Hipster', 'Q3_16_Hipster', 'Q4_16_Hipster', 'Q1_17_Hipster', 'Q2_17_Hipster', 'Q3_17_Hipster', 'Q4_17_Hipster', 'Q1_16_Beautiful_Scenery', 'Q2_16_Beautiful_Scenery', 'Q3_16_Beautiful_Scenery', 'Q4_16_Beautiful_Scenery', 'Q1_17_Beautiful_Scenery', 'Q2_17_Beautiful_Scenery', 'Q3_17_Beautiful_Scenery', 'Q4_17_Beautiful_Scenery', 'Foodie_16', 'Foodie_17', 'lic_code_cat', 'district_cat', 'Nature_Exp', 'Family_Fun', 'Healthy_Lifestyle', 'Nightlife_Hotspot', 'Artsy', 'Foodie', 'Hipster', 'Beautiful_Scenery']\n"
     ]
    }
   ],
   "source": [
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df[[\n",
    "    'isClosed','Nature_Exp', 'Family_Fun', 'Healthy_Lifestyle', 'Nightlife_Hotspot', 'Artsy', 'Foodie', 'Hipster', 'Beautiful_Scenery'\n",
    "]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 8) (320,)\n"
     ]
    }
   ],
   "source": [
    "# loading libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# create design matrix X and target vector y\n",
    "# X = np.array(df.ix[:, 0:4]) \t# end index is exclusive\n",
    "# y = np.array(df['lic_code_cat']) \t# another way of indexing a pandas df\n",
    "\n",
    "target = df_reg['isClosed']\n",
    "# target_names = [\"Open\",\"Closed\"]\n",
    "data = df_reg.drop(\"isClosed\", axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 0.996/0.725\n",
      "k: 3, Train/Test Score: 0.858/0.800\n",
      "k: 5, Train/Test Score: 0.833/0.825\n",
      "k: 7, Train/Test Score: 0.787/0.825\n",
      "k: 9, Train/Test Score: 0.796/0.850\n",
      "k: 11, Train/Test Score: 0.796/0.838\n",
      "k: 13, Train/Test Score: 0.787/0.863\n",
      "k: 15, Train/Test Score: 0.796/0.887\n",
      "k: 17, Train/Test Score: 0.796/0.887\n",
      "k: 19, Train/Test Score: 0.796/0.887\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=13 Test Acc: 0.863\n"
     ]
    }
   ],
   "source": [
    "# Note that k: 13 seems to be the best choice for this dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train, y_train)\n",
    "print('k=13 Test Acc: %.3f' % knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://github.com/alifier/Restaurant_success_model/blob/master/Restaurants_yelp_ML_final.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf_A = GaussianNB()\n",
    "clf_B = DecisionTreeClassifier(random_state=1)\n",
    "clf_C = GradientBoostingClassifier(random_state=1)\n",
    "clf_D = RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in features and target\n",
    "df_ml_features = df_reg\n",
    "df_ml_target = df['Lifespan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_ml_features, df_ml_target, test_size = 0.2, random_state = 10,\\\n",
    "                                                    stratify = df_ml_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,list(y_train.values))\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Accuracy: ',clf.score(X_test,list(y_test.values)))\n",
    "print('Precision: ',precision_score(list(y_test.values),y_pred))\n",
    "print('Recall: ',recall_score(list(y_test.values),y_pred))\n",
    "print('F1 Score: ',f1_score(list(y_test.values),y_pred))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(list(y_test.values), y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
